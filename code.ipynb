{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dee5cfb-a69f-4274-8764-1234409bc987",
   "metadata": {},
   "source": [
    "### Connecting to the Stat-Xplore API using Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "323f5040-5a22-4c5e-9a95-f45d66cc4e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statxplore import http_session\n",
    "from statxplore import objects\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pathlib\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be692f16-43c1-4016-808e-c7bebbf867a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = http_session.StatSession(api_key='your_api_key_here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16d7b0fd-94b4-401d-ac17-037211683a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "myPath = (f\"C:\\\\your\\\\file\\\\path\\\\here\")\n",
    "queriedPath = (f\"C:\\\\your\\\\file\\\\path\\\\here\\\\Queried\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe518b7f-3b5c-4aba-9ea2-24fb046ba8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []  # Initialize an empty list to store results\n",
    "file_count = 0\n",
    "for json_file in pathlib.Path(myPath).glob('*.json'):\n",
    "    file_name = json_file.name\n",
    "    file_count = file_count + 1\n",
    "    \n",
    "    with open(json_file) as f:  # Use 'with' to handle file opening and closing automatically\n",
    "        query = json.load(f)\n",
    "    \n",
    "    queryString = json.dumps(query)\n",
    "    data = objects.Table.query_json(session, queryString)  # Initialize session\n",
    "    \n",
    "    shutil.move(json_file, queriedPath) #move the queried file to a new directory\n",
    "    series = pd.Series(data)\n",
    "    \n",
    "    # Access row-level information\n",
    "    rows = [item['labels'][0] for item in series.fields[0]['items']]\n",
    "    \n",
    "    # Access column headers\n",
    "    cols = [item['labels'][0] for item in series.fields[1]['items']]\n",
    "    \n",
    "    # Access wafer values\n",
    "    wafer = [item['labels'][0] for item in series.fields[2]['items']]\n",
    "    \n",
    "    # Create new column headers by combining cols and wafer\n",
    "    newColHeaders = [f\"{col} - {waferItem}\" for col in cols for waferItem in wafer]\n",
    "    \n",
    "    # Retrieve cube data and reshape the values list into a 2D array\n",
    "    cube_data = series.cubes\n",
    "    if cube_data:  # Ensure cube_data is not empty\n",
    "        key = next(iter(cube_data))\n",
    "        values_list = cube_data[key]['values']\n",
    "        \n",
    "        reshaped_values = np.array(values_list).reshape(-1, len(newColHeaders))\n",
    "        \n",
    "        # Create DataFrame with reshaped values and correct column headers\n",
    "        df = pd.DataFrame(reshaped_values, columns=newColHeaders)\n",
    "        df['category'] = rows\n",
    "        df['file'] = file_name\n",
    "        \n",
    "        # Append the DataFrame to the result list\n",
    "        result.append(df)\n",
    "\n",
    "# Now, 'result' contains a list of DataFrames, one for each JSON file processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "894fd9ea-bacd-4de0-9688-430fd70bf5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat(result, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2420d9ae-ea42-4221-967f-6e5c8ccc5508",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02265f31-7eef-44fe-b240-1e1478b27c80",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45efb60-50b6-49f4-afa4-23c638d73f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There were {file_count} .json file(s) loaded into the folder\\n\")\n",
    "\n",
    "print(\"Those files are: \")\n",
    "for json_file in pathlib.Path(myPath).glob('*.json'):\n",
    "    print(json_file.name)\n",
    "\n",
    "loaded_file_count = len(pd.unique(final_df['file']))\n",
    "print(\"\")\n",
    "print(f\"There are {loaded_file_count} file(s) loaded into the DataFrame\")\n",
    "print(\"\\nThose files are: \")\n",
    "for item in pd.unique(final_df['file']):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150f7f6c-4536-4e56-901a-8dde696ee78b",
   "metadata": {},
   "source": [
    "Convert the above validation step to a code line and execute to view the number of json files stored in the file path provided, with the file names listed as well as the number of unique files stored in the DataFrame and their values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a9937e-b192-4531-9feb-2004baa34b76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
